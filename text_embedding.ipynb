{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/Ali-Alameer/NLP/blob/main/text_embedding.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Token based text embedding trained on English Google News 7B corpus.\n",
        "Text embedding based on feed-forward Neural-Net Language Models[1] with pre-built OOV. Maps from text to 50-dimensional embedding vectors.\n",
        "\n",
        "Details\n",
        "Based on NNLM with two hidden layers.\n",
        "\n",
        "Input\n",
        "The module takes a batch of sentences in a 1-D tensor of strings as input.\n",
        "\n",
        "Preprocessing\n",
        "The module preprocesses its input by splitting on spaces.\n",
        "\n",
        "Out of vocabulary tokens\n",
        "Small fraction of the least frequent tokens and embeddings (~2.5%) are replaced by hash buckets. Each hash bucket is initialized using the remaining embedding vectors that hash to the same bucket.\n",
        "\n",
        "Sentence embeddings\n",
        "Word embeddings are combined into sentence embedding using the sqrtn combiner (see tf.nn.embedding_lookup_sparse).\n",
        "\n",
        "References\n",
        "[1] Yoshua Bengio, RÃ©jean Ducharme, Pascal Vincent, Christian Jauvin. A Neural Probabilistic Language Model. Journal of Machine Learning Research, 3:1137-1155, 2003."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## The saved model can be loaded directly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0oj4HS26x05",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alf2kDHJ60rO",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "embed = hub.load(\"https://tfhub.dev/google/nnlm-en-dim50/2\")\n",
        "embeddings = embed([\"cat is on the mat\", \"dog is in the fog\"])\n",
        "embeddings"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "tokenizers.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
