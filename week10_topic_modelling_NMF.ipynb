{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ali-Alameer/NLP/blob/main/week10_topic_modelling_NMF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c7GHBxs6cvRJ"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkE2ISRtdGNq",
        "outputId": "271276ab-f985-46d5-c5d0-7ec840bc9030"
      },
      "outputs": [],
      "source": [
        "# Data processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Text preprocessiong\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "wn = nltk.WordNetLemmatizer()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset read and visualise "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "9td3G8tgX9JO",
        "outputId": "0145d3bc-6be3-43b6-8b64-b6e3ec8a26da"
      },
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "import urllib.request\n",
        "    \n",
        "url = urllib.request.urlopen(\"https://github.com/Ali-Alameer/NLP/raw/main/data/NIPS%20Papers.zip\")\n",
        "\n",
        "with ZipFile(BytesIO(url.read())) as my_zip_file:\n",
        "    temp = my_zip_file.open('NIPS Papers/papers.csv')\n",
        "\n",
        "papers_nips = pd.read_csv(temp)\n",
        "\n",
        "# Print head\n",
        "papers_nips.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "RvjzYnsXdSMF",
        "outputId": "cd992747-d395-4e2e-aea2-7a22e9092703"
      },
      "outputs": [],
      "source": [
        "papers_nips.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVmGNNlodYhi",
        "outputId": "cb6b67e2-a3c1-4d32-880f-c080eafb468c"
      },
      "outputs": [],
      "source": [
        "# Remove stopwords\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "print(f'There are {len(stopwords)} default stopwords. They are {stopwords}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "iSZcQsQYdgQ-",
        "outputId": "946061ad-83d7-46ef-80ca-39de3f3430f3"
      },
      "outputs": [],
      "source": [
        "# Remove stopwords\n",
        "papers_nips['abstract_without_stopwords'] = papers_nips['paper_text'].apply(lambda x: ' '.join([w for w in x.split() if w.lower() not in stopwords]))\n",
        "# Lemmatization\n",
        "papers_nips['abstract_lemmatized'] = papers_nips['abstract_without_stopwords'].apply(lambda x: ' '.join([wn.lemmatize(w) for w in x.split() if w not in stopwords]))\n",
        "# Take a look at the data\n",
        "papers_nips.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parameters selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SvVdcwXFdn4F"
      },
      "outputs": [],
      "source": [
        "n_samples = 2000\n",
        "n_features = 1000\n",
        "n_components = 10\n",
        "n_top_words = 20\n",
        "batch_size = 128\n",
        "init = \"nndsvda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iN9hLa10do1f"
      },
      "outputs": [],
      "source": [
        "def plot_top_words(model, feature_names, n_top_words, title):\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(30, 15), sharex=True)\n",
        "    axes = axes.flatten()\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        top_features_ind = topic.argsort()[: -n_top_words - 1 : -1]\n",
        "        top_features = [feature_names[i] for i in top_features_ind]\n",
        "        weights = topic[top_features_ind]\n",
        "\n",
        "        ax = axes[topic_idx]\n",
        "        ax.barh(top_features, weights, height=0.7)\n",
        "        ax.set_title(f\"Topic {topic_idx +1}\", fontdict={\"fontsize\": 30})\n",
        "        ax.invert_yaxis()\n",
        "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
        "        for i in \"top right left\".split():\n",
        "            ax.spines[i].set_visible(False)\n",
        "        fig.suptitle(title, fontsize=40)\n",
        "\n",
        "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFOXvY5cdwFL",
        "outputId": "3e505147-1f24-49ff-879d-3c32e022131b"
      },
      "outputs": [],
      "source": [
        "print(\"Extracting tf-idf features for NMF...\")\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_df=0.95, min_df=2, max_features=n_features, stop_words=\"english\"\n",
        ")\n",
        "tfidf = tfidf_vectorizer.fit_transform(papers_nips['abstract_lemmatized'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFwWQjyjeQMR",
        "outputId": "87c24e15-8529-4cdc-f1a5-873bcffa97c1"
      },
      "outputs": [],
      "source": [
        "print(\"Extracting tf features for LDA...\")\n",
        "tf_vectorizer = CountVectorizer(\n",
        "    max_df=0.95, min_df=2, max_features=n_features, stop_words=\"english\"\n",
        ")\n",
        "tf = tf_vectorizer.fit_transform(papers_nips['abstract_lemmatized'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "15UiveaMeiTa",
        "outputId": "8a6beb26-3e95-4e91-b09b-1cc15b78af32"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    \"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
        "    \"n_samples=%d and n_features=%d...\" % (n_samples, n_features)\n",
        ")\n",
        "nmf = NMF(\n",
        "    n_components=n_components,\n",
        "    random_state=1,\n",
        "    init=init,\n",
        "    beta_loss=\"frobenius\",\n",
        "    alpha_W=0.00005,\n",
        "    alpha_H=0.00005,\n",
        "    l1_ratio=1,\n",
        ").fit(tfidf)\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "plot_top_words(\n",
        "    nmf, tfidf_feature_names, n_top_words, \"Topics in NMF model (Frobenius norm)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        },
        "id": "Pxa8u2vje2JG",
        "outputId": "37e78047-0daf-4e04-b4e6-1edbdf959016"
      },
      "outputs": [],
      "source": [
        "# Fit the NMF model\n",
        "print(\n",
        "    \"\\n\" * 2,\n",
        "    \"Fitting the NMF model (generalized Kullback-Leibler \"\n",
        "    \"divergence) with tf-idf features, n_samples=%d and n_features=%d...\"\n",
        "    % (n_samples, n_features),\n",
        ")\n",
        "nmf = NMF(\n",
        "    n_components=n_components,\n",
        "    random_state=1,\n",
        "    init=init,\n",
        "    beta_loss=\"kullback-leibler\",\n",
        "    solver=\"mu\",\n",
        "    max_iter=1000,\n",
        "    alpha_W=0.00005,\n",
        "    alpha_H=0.00005,\n",
        "    l1_ratio=0.5,\n",
        ").fit(tfidf)\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "plot_top_words(\n",
        "    nmf,\n",
        "    tfidf_feature_names,\n",
        "    n_top_words,\n",
        "    \"Topics in NMF model (generalized Kullback-Leibler divergence)\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828
        },
        "id": "oE8jpRsffWb4",
        "outputId": "62e47f96-8e63-4e2f-82cf-1b6dd01be773"
      },
      "outputs": [],
      "source": [
        "lda = LatentDirichletAllocation(\n",
        "    n_components=n_components,\n",
        "    max_iter=5,\n",
        "    learning_method=\"online\",\n",
        "    learning_offset=50.0,\n",
        "    random_state=0,\n",
        ")\n",
        "lda.fit(tf)\n",
        "tf_feature_names = tf_vectorizer.get_feature_names_out()\n",
        "plot_top_words(lda, tf_feature_names, n_top_words, \"Topics in LDA model\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
