{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXH1bmUctMld"
      },
      "source": [
        "# Unicode strings\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/Ali-Alameer/NLP/blob/main/unicode_strings.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrHJrKYis06U"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "NLP models often handle different languages with different character sets.  *Unicode* is a standard encoding system that is used to represent characters from almost all languages.  Every Unicode character is encoded using a unique integer [code point](https://en.wikipedia.org/wiki/Code_point) between `0` and `0x10FFFF`. A *Unicode string* is a sequence of zero or more code points.\n",
        "\n",
        "This tutorial shows how to represent Unicode strings in TensorFlow and manipulate them using Unicode equivalents of standard string ops. It separates Unicode strings into tokens based on script detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIKHl5Lvn4gh",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-LkcI-vtWNj"
      },
      "source": [
        "## The `tf.string` data type\n",
        "\n",
        "The basic TensorFlow `tf.string` `dtype` allows you to build tensors of byte strings.\n",
        "Unicode strings are [utf-8](https://en.wikipedia.org/wiki/UTF-8) encoded by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yo-Qv6ntaFr",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tf.constant(u\"Thanks üòä\") # unicode strings are indicated by the \"u\" prefix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kA1ziG2tyCT"
      },
      "source": [
        "A `tf.string` tensor treats byte strings as atomic units. This enables it to store byte strings of varying lengths. The string length is not included in the tensor dimensions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyINCmTztyyS",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tf.constant([u\"You're\", u\"welcome!\"]).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsMPnjb6UDJ1"
      },
      "source": [
        "If you use Python to construct strings, note that [string literals](https://docs.python.org/3/reference/lexical_analysis.html) are Unicode-encoded by default."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUFZ7B1Lk-uj"
      },
      "source": [
        "## Representing Unicode\n",
        "\n",
        "There are two standard ways to represent a Unicode string in TensorFlow:\n",
        "\n",
        "* `string` scalar ‚Äî where the sequence of code points is encoded using a known [character encoding](https://en.wikipedia.org/wiki/Character_encoding).\n",
        "* `int32` vector ‚Äî where each position contains a single code point.\n",
        "\n",
        "For example, the following three values all represent the Unicode string `\"ËØ≠Ë®ÄÂ§ÑÁêÜ\"` (which means \"language processing\" in Chinese):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjQIkfJWvC_u",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Unicode string, represented as a UTF-8 encoded string scalar.\n",
        "text_utf8 = tf.constant(u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\")\n",
        "text_utf8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQqcUECcvF2r",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Unicode string, represented as a UTF-16-BE encoded string scalar.\n",
        "text_utf16be = tf.constant(u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\".encode(\"UTF-16-BE\"))\n",
        "text_utf16be"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExdBr1t7vMuS",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Unicode string, represented as a vector of Unicode code points.\n",
        "text_chars = tf.constant([ord(char) for char in u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\"])\n",
        "text_chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8czv4JNpBnZ"
      },
      "source": [
        "### Converting between representations\n",
        "\n",
        "TensorFlow provides operations to convert between these different representations:\n",
        "\n",
        "* `tf.strings.unicode_decode`: Converts an encoded string scalar to a vector of code points.\n",
        "* `tf.strings.unicode_encode`: Converts a vector of code points to an encoded string scalar.\n",
        "* `tf.strings.unicode_transcode`: Converts an encoded string scalar to a different encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qb-UQ_oLpAJg",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tf.strings.unicode_decode(text_utf8,\n",
        "                          input_encoding='UTF-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEBUcunnp-9n",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tf.strings.unicode_encode(text_chars,\n",
        "                          output_encoding='UTF-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MLhWcLZrph-",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tf.strings.unicode_transcode(text_utf8,\n",
        "                             input_encoding='UTF8',\n",
        "                             output_encoding='UTF-16-BE')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVeLeVohqN7I"
      },
      "source": [
        "### Batch dimensions\n",
        "\n",
        "When decoding multiple strings, the number of characters in each string may not be equal.  The return result is a [`tf.RaggedTensor`](../../guide/ragged_tensor.ipynb), where the innermost dimension length varies depending on the number of characters in each string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2jVzPymr_Mm",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# A batch of Unicode strings, each represented as a UTF8-encoded string.\n",
        "batch_utf8 = [s.encode('UTF-8') for s in # Encode str to UTF-8 bytes: s.encode('utf-8')\n",
        "              [u'h√Éllo', u'What is the weather tomorrow', u'G√∂√∂dnight', u'üòä']]\n",
        "batch_chars_ragged = tf.strings.unicode_decode(batch_utf8,\n",
        "                                               input_encoding='UTF-8')\n",
        "for sentence_chars in batch_chars_ragged.to_list():\n",
        "  print(sentence_chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRh3n1hPsJ9v"
      },
      "source": [
        "You can use this `tf.RaggedTensor` directly, or convert it to a dense `tf.Tensor` with padding or a `tf.sparse.SparseTensor` using the methods `tf.RaggedTensor.to_tensor` and `tf.RaggedTensor.to_sparse`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz17yeSMsUid",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "batch_chars_padded = batch_chars_ragged.to_tensor(default_value=-1)\n",
        "print(batch_chars_padded.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBjsPQp3rhfm",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "batch_chars_sparse = batch_chars_ragged.to_sparse()\n",
        "# the code below extract each of the SparseTensor elements and print them in a padded \"_\" style for visualisation (nurdy way but worth understanding the way its implemented)\n",
        "nrows, ncols = batch_chars_sparse.dense_shape.numpy() # get the shape of the sparse tensor and convert shape to numpy array\n",
        "elements = [['_' for i in range(ncols)] for j in range(nrows)] # the elements is a list with values of \"_\" with size 4 x 28\n",
        "for (row, col), value in zip(batch_chars_sparse.indices.numpy(), batch_chars_sparse.values.numpy()):\n",
        "  elements[row][col] = str(value)\n",
        "# max_width = max(len(value) for row in elements for value in row)\n",
        "value_lengths = []\n",
        "for row in elements:\n",
        "  for value in row:\n",
        "    value_lengths.append(len(value))\n",
        "max_width = max(value_lengths)\n",
        "print('[%s]' % '\\n '.join( # The %s token allows to insert a string. Notice that the %s token is replaced by whatever we pass to the string after the % symbol. \"\\n\" indicate end of line\n",
        "    '[%s]' % ', '.join(value.rjust(max_width) for value in row) # .rjust returns the string right justified in a string of length width\n",
        "    for row in elements))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "details about the zip function: The zip() function returns a zip object, which is an iterator of tuples where the first item in each passed iterator is paired together, and then the second item in each passed iterator are paired together etc.\n",
        "\n",
        "If the passed iterators have different lengths, the iterator with the least items decides the length of the new iterator.\n",
        "\n",
        "a = (\"John\", \"Charles\", \"Mike\")\n",
        "b = (\"Jenny\", \"Christy\", \"Monica\")\n",
        "\n",
        "x = zip(a, b)\n",
        "\n",
        "#use the tuple() function to display a readable version of the result:\n",
        "\n",
        "print(tuple(x))\n",
        "(('John', 'Jenny'), ('Charles', 'Christy'), ('Mike', 'Monica'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCCkZh-nwlbL"
      },
      "source": [
        "When encoding multiple strings with the same lengths, use a `tf.Tensor` as the input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lP62YUAwjK9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tf.strings.unicode_encode([[99, 97, 116], [100, 111, 103], [99, 111, 119]],\n",
        "                          output_encoding='UTF-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w58CMRg9tamW"
      },
      "source": [
        "When encoding multiple strings with varying length, use a `tf.RaggedTensor` as the input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7GtOtrltaMl",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tf.strings.unicode_encode(batch_chars_ragged, output_encoding='UTF-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "batch_chars_ragged # input is multiple strings with varying length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2Nh5Aj9xob3"
      },
      "source": [
        "If you have a tensor with multiple strings in padded or sparse format, convert it first into a `tf.RaggedTensor` before calling `tf.strings.unicode_encode`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2bYCYl0u-Ue",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tf.strings.unicode_encode(\n",
        "    tf.RaggedTensor.from_sparse(batch_chars_sparse),\n",
        "    output_encoding='UTF-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlV2znh_u_zm",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tf.strings.unicode_encode(\n",
        "    tf.RaggedTensor.from_tensor(batch_chars_padded, padding=-1),\n",
        "    output_encoding='UTF-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQOOGkscvDpc"
      },
      "source": [
        "## Unicode operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkmtsA_yvMB0"
      },
      "source": [
        "### Character length\n",
        "\n",
        "Use the `unit` parameter of the `tf.strings.length` op to indicate how character lengths should be computed.  `unit` defaults to `\"BYTE\"`, but it can be set to other values, such as `\"UTF8_CHAR\"` or `\"UTF16_CHAR\"`, to determine the number of Unicode codepoints in each encoded string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZzMe59mvLHr",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Note that the final character takes up 4 bytes in UTF8.\n",
        "thanks = u'Thanks üòä'.encode('UTF-8') #  unicode strings are indicated by the \"u\" prefix.  UTF-8 is a variable-width character encoding\n",
        "num_bytes = tf.strings.length(thanks).numpy()\n",
        "num_chars = tf.strings.length(thanks, unit='UTF8_CHAR').numpy()\n",
        "print('{} bytes; {} UTF-8 characters'.format(num_bytes, num_chars))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHG85gxlvVU0"
      },
      "source": [
        "### Character substrings\n",
        "\n",
        "The `tf.strings.substr` op accepts the `unit` parameter, and uses it to determine what kind of offsets the `pos` and `len` paremeters contain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each string in the input Tensor, creates a substring starting at index pos with a total length of len.\n",
        "\n",
        "If len defines a substring that would extend beyond the length of the input string, or if len is negative, then as many characters as possible are used.\n",
        "\n",
        "A negative pos indicates distance within the string backwards from the end.\n",
        "\n",
        "If pos specifies an index which is out of range for any of the input strings, then an InvalidArgumentError is thrown.\n",
        "\n",
        "pos and len must have the same shape, otherwise a ValueError is thrown on Op creation.\n",
        "\n",
        "input = [b'Hello', b'World']\n",
        "position = 1\n",
        "length = 3\n",
        "\n",
        "output = [b'ell', b'orl']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlWRLV-4xWYq",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Here, unit='BYTE' (default). Returns a single byte with len=1\n",
        "tf.strings.substr(thanks, pos=7, len=1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfNUVDPwxkCS",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Specifying unit='UTF8_CHAR', returns a single 4 byte character in this case\n",
        "print(tf.strings.substr(thanks, pos=7, len=1, unit='UTF8_CHAR').numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJUEsVSyeIa3"
      },
      "source": [
        "### Split Unicode strings\n",
        "\n",
        "The `tf.strings.unicode_split` operation splits unicode strings into substrings of individual characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDjkh5G1ejMt",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tf.strings.unicode_split(thanks, 'UTF-8').numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQqEEZEbdG9O"
      },
      "source": [
        "### Byte offsets for characters\n",
        "\n",
        "To align the character tensor generated by `tf.strings.unicode_decode` with the original string, it's useful to know the offset for where each character begins.  The method `tf.strings.unicode_decode_with_offsets` is similar to `unicode_decode`, except that it returns a second tensor containing the start offset of each character."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cug7cmwYdowd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "codepoints, offsets = tf.strings.unicode_decode_with_offsets(u'üéàüéâüéä', 'UTF-8')\n",
        "\n",
        "for (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):\n",
        "  print('At byte offset {}: codepoint {}'.format(offset, codepoint))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "try different combinations of characters for the above and check the results "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZnCNxOvx66T"
      },
      "source": [
        "## Unicode scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRRHqkqNyGZ6"
      },
      "source": [
        "Each Unicode code point belongs to a single collection of codepoints known as a [script](https://en.wikipedia.org/wiki/Script_%28Unicode%29) .  A character's script is helpful in determining which language the character might be in. For example, knowing that '–ë' is in Cyrillic script indicates that modern text containing that character is likely from a Slavic language such as Russian or Ukrainian.\n",
        "\n",
        "TensorFlow provides the `tf.strings.unicode_script` operation to determine which script a given codepoint uses. The script codes are `int32` values corresponding to [International Components for\n",
        "Unicode](http://site.icu-project.org/home) (ICU) [`UScriptCode`](http://icu-project.org/apiref/icu4c/uscript_8h.html) values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7DeYHrRyFPy",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "uscript = tf.strings.unicode_script([33464, 1041])  # ['Ëä∏', '–ë']\n",
        "\n",
        "print(uscript.numpy())  # [17, 8] == [USCRIPT_HAN, USCRIPT_CYRILLIC]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fW992a1lIY6"
      },
      "source": [
        "The `tf.strings.unicode_script` operation can also be applied to multidimensional `tf.Tensor`s or `tf.RaggedTensor`s of codepoints:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uR7b8meLlFnp",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "print(tf.strings.unicode_script(batch_chars_ragged))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oL9KopJirB2g"
      ],
      "name": "unicode.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
